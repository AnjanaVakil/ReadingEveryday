# 线程引入的开销

对于为了提升性能而引入的线程来说，并行带来的性能的提升必须超过并发导致的开销。

## 上下文切换

如果可运行的线程数大于CPU的数量，那么操作系统最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU，这将导致一次上下文切换，在这个过程中保存当前运行线程的**执行上下文**并将新调度进来的线程的执行上下文设置为**当前上下文。**

**上下文（context）：实际上只是上文，包含了需要的变量等环境信息**

切换上下文需要一定的开销：

1. 线程调度过程中需要访问由 JVM 和操作系统的共享的数据结构的开销
2. 新的线程被切换进来的时候，所需数据可能不在当前处理器的本地缓存中，可能导致缓存缺失。


上下文切换的实际开销会随着平台的不同而变化，经验来看，大多数通用处理器中，上下文切换的开销相当于5000-10000个时钟周期，也就是几微秒。

Unix的vmstat命令能报告上下文切换次数以及在内核中执行时间所占比例等信息，如果内核占用率较高（超过10%），那么通常表示调度活跃发生的很频繁，这很可能是由于I/O或者竞争锁导致的阻塞引起的。

## 内存同步

synchronized 和 volatile 提供的可见性保证中可能会使用一些特殊指令，即内存栅栏（Memory Barrier）。内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓存，以及停止执行管道。内存栅栏为了防止重排序，它会抑制一些编译器优化操作，然后影响性能。



无竞争的同步对性能的影响微乎其微。有竞争的同步。

现代 JVM 能通过优化来消除一些不会发生竞争的锁，如果一个锁对象只能由当前线程访问，那么 JVM 会去掉这个锁操作。

一些更完备的 JVM 能通过逸出分析来找出不会发布到堆到本地对象引用（因此这个引用是线程本地的），如果不对 getStoogeNames 进行优化，那么至少会将 Vector 上的锁获取/释放 4 次。但 JVM 可以分析这些调用，当能确保它的内部状态不会逸出时，就可以去掉这 4 次的锁获取开销。

```java
public String getStoogeNames() {
	List<String> stooges = new Vector<String>();
    stooges.add("1");
    stooges.add("1");
    stooges.add("1");
    return stooges.toString();
}
```



编译器执行**锁粒度粗化**也能对getStoogeNames 进行优化，把邻近的同步代码块用同一个锁合并起来，那 4 次拿锁的动作就可以减少到 1 次。

某个线程中的同步可能会影响其他线程的性能。同步会增加共享内存总线上的通信量，总线的带宽是有限的，并且所有的处理器都将依赖这条总线。如果有多个线程竞争同步带宽，那么所有使用了同步的线程都会受到影响。



## 阻塞

非竞争的同步可以完全在 JVM 中进行处理，而竞争的同步则可能需要操作系统的介入，从而增加开销。

当在锁上发生竞争时，竞争失败的线程肯定会阻塞，JVM 在实现阻塞行为时，

1.  可以采用自旋等待（Spin-Waiting, 指通过循环不断地尝试获取锁，知道成功）；
2. 或者通过操作系统挂起被阻塞的线程。

这两种方式的效率高低，要取决于上下文切换的开销以及在成功获取锁之前需要等待的时间。如果等待时间较短，则适合自旋锁，反之则适合线程挂起方式。大多数 JVM 在等待锁时都只是将线程挂起。



# 减少锁的竞争

串行操作会降低可伸缩性，上下文切换会降低性能。锁上发生竞争时将同时导致这两种问题，因此减少锁的竞争可以提高性能和可伸缩性。

另外，独占锁对资源的保护是通过每次只有一个线程能访问的串行方式，如果在锁上持续发生竞争，那么将减少可伸缩性。

有两个因素影响在锁上发生竞争的可能性：锁的请求频率，以及每次持有该锁的时间。如果两者的乘积很小，那么大部分获取锁的操作都不会发生竞争。

有三种方式可以降低锁的竞争程度：

1. 减少锁的持有时间
2. 减少锁的请求频率
3. 使用带有协调机制的独占锁，这些机制允许更高的并发性



## 缩小锁的范围

其实就是缩短锁的持有时间：将一些无关的代码移出同步代码块，尤其是开销较大的操作。

如果只有一个状态变量，或者可能的情况下，甚至可以将线程安全委托给其他的类来进一步提升性能，比如委托给 ConcurrentHashmap，这样相比于主动加锁，实际上锁的持有时间在 map 内部变得更小了。


## 减少锁的粒度

**Reducing lock granularity**

降低线程请求锁的频率可以通过锁分解和锁分段等技术来实现，在这些技术中将采用多个独立的锁来保护独立的状态变量，从而改变这些变量之前由单个锁来保护的情况。这些技术能减少锁操作的粒度，实现更高的可伸缩性，然而，使用的锁越多，那么发生死锁的风险也会越高。

如果一个锁需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而可以减少发生锁竞争的可能性，因为相比于很多线程竞争同一个锁时，多把锁中，很多线程竞争同一把锁的概率就会降低，从而提高可伸缩性，并最终降低每个锁被请求的频率。
