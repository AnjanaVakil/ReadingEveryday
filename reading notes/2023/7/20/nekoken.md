# 机器学习 - 曹佳老师笔记

## 分类、回归、聚类、降维的区别

<img src="https://img-blog.csdn.net/20160119110440871" alt="这里写图片描述" style="zoom:30%;" />

给定一个样本特征 , 我们希望预测其对应的属性值 , 如果是离散的, 那么这就是一个分类问题；反之，如果是连续的实数, 这就是一个回归问题。

如果给定一组样本特征 , 我们没有对应的属性值 , 而是想发掘这组样本在几维空间的分布, 比如分析哪些样本靠的更近，哪些样本之间离得很远，这就是属于聚类问题。

如果我们想用维数更低的子空间来表示原来高维的特征空间，那么这就是降维问题。

分类(classification)和回归(regression)：

无论是分类还是回归，都是想建立一个预测模型 ，给定一个输入  , 可以得到一个输出 : 

不同的只是在分类问题中,  是离散的；而在回归问题中是连续的。所以总得来说，两种问题的学习算法都很类似。所以在这个图谱上，我们看到在分类问题中用到的学习算法，在回归问题中也能使用。分类问题最常用的学习算法包括SVM (支持向量机) ，SGD (随机梯度下降算法)，Bayes (贝叶斯估计)，Ensemble，KNN等。而回归问题也能使用SVR, SGD, Ensemble等算法，以及其它线性回归算法。

聚类(clustering)：

聚类也是分析样本的属性，有点类似classification，不同的就是classification在预测之前是知道的范围，或者说知道到底有几个类别，而聚类是不知道属性的范围的。所以classification也常常被称为supervised learning，而clustering就被称为unsupervised learning。 

clustering事先不知道样本的属性范围，只能凭借样本在特征空间的分布来分析样本的属性。这种问题一般更复杂，而常用的算法包括k-means(K-均值)，GMM(高斯混合模型)等。

降维(dimensionality reduction)：

应用：特征的维数过高，会增加训练的负担与存储空间，降维就是希望去除特征的冗余，用更加少的维数来表示特征。降维算法最基础的就是PCA了，后面的很多算法都是以PCA为基础演化而来。

## 第一章 绪论

+ 机器学习的定义：机器学习研究和构建的是一种特殊算法（**而非某一个特定的算法**），能够让计算机自己在数据中学习从而进行预测。
  + 针对任务T，性能P随着经验而不断增加。

+ 构建模型：收集数据、数据预处理、机器学习模型的构建和选择、模型评估、模型发布。

+ 模型应用：收集数据、数据预处理、基于模型进行计算、结果展示。

+ 基本术语

  + 数据集：表格数据、文本、图形图像、语音、视频

  + 训练集和测试集：

    训练集：被学习的数据

    测试集：评估学习效果的数据

    + <img src="assets/image-20230718105706282.png" alt="image-20230718105706282" style="zoom:25%;" />

    特征、属性、维度

    + <img src="assets/image-20230718105955352.png" alt="image-20230718105955352" style="zoom:25%;" />
    + 列$(X_1,X_2,X_3)$是特征/属性和维度，独立变量
    + 行是数据/点/距离/样本/记录
    + 列$(Y)$是要预测的目标/结果/响应/标签（标记）/因变量的特殊列。
    + 图片样本：看作像素矩阵(height * width * dimension)

    标签数据 labeled data

    + 有标签的数据集：有Y值
    + 鸾尾花数据集

    数据增强

    + 人工从已有的数据中增加一些新数据
    + 例如图片数据

+ 机器学习分类：

  + 基于学习策略的分类
    + **模拟人脑、采用数学统计的方法**

  + 基于学习方法的分类
    + **归纳学习、演绎学习、类比学习**

  + 基于数据形式的分类
    + **结构化学习、非结构化学习**

  + 基于数据集是否有标记的分类
    + 监督学习、无监督学习、半监督学习、强化学习……
    
    + 监督学习：Supervised Learning
      + 数据集带标签：通过训练数据来学习映射函数，其中输入变量为X，输出变量为Y。Y=f(X)
      
      + <img src="assets/image-20230718115603382.png" alt="image-20230718115603382" style="zoom:33%;" />
      
      + 监督学习
      
        + 泛化：一个机器学习模型能够对没见过的数据做出准确判断。
      
        + 术语使用：某个模型能够从训练集较好地泛化到测试集，提高模型的泛化能力
      
        + 典型任务：Y是连续的数(回归，红)，Y是离散的数(分类)。
      
          <img src="assets/image-20230719163032258.png" alt="image-20230719163032258" style="zoom:33%;" />
      
    + 无监督学习方法
      
      + 数据集无标签：只有输入变量$X$，无输出变量。
      + 获取训练数据的潜在结构。
      + 解决任务：关联分析、聚类、降维、异常检测。
      
    + 关联分析
      
      + 两个(几个)变量之间的关系















+ 聚类：基于样本的相似性，将无标签数据分组

+ 降维：降低维度，减少特征

+ 关联分析：寻找变量之间的关系

### 聚类

+ 目标：将相似的样本归位一组。组/簇 group/cluster。聚类操作输出结果：由多个簇组成，即一次样本集的划分。

+ 聚类概述：没有统一的定义，衡量相似性的方法也不同，不同的算法会得到不同的聚类结果。在不同的应用中，不同的聚类结果有不同的解释。

+ 应用：推荐系统、搜索引擎、流媒体服务(基于用户每天观看次数、每个星期观看次数、观看媒体类型、观看后评价等信息)。

+ 聚类方法：K-means、基于密度的聚类DBSCAN、层次聚类…

+ 普通聚类和重叠聚类：

  + Exclusive Clustering

    + 每个样本点只会被分到一组里
    + 方法K-Means

  + Overlapping Clustering

    + 存在一些样本点，可能被分到多组里
    + 方法fuzzy K-Means……

  + K-means方法步骤

    + 第一步：选择一个K值，表示将要分为K组；

    + 第二步：随机选择K个节点，计算每个其他节点到这些节点的距离，将每个其他节点分别归到这K个节点上；

    + 第三步：重复执行下列步骤，直到各个节点被稳定不变地分配到各个组里；

      1. 计算每个组的质心（均值）
      2. 计算所有节点到各个质心的距离，并且将每个节点按最近距离分配到各个组里

    + 例子：

      ```python
      import pandas as pd
      import numpy as np
      from sklearn.cluster import KMeans
      
      iris=pd.read_csv("iris.csv")
      x=iris.drop(columns=['variety'])
      x=x.apply(lambda v:(v-np.mean(v))/np.std(v))
      x=np.c_[[1]*x.shape[0],x]
      
      
      km = KMeans(n_clusters=3, random_state=0)
      vv= km.fit_predict(x)
      
      a=np.array([[0.2,0.7,0.3,0.2]])
      a=np.c_[[1]*a.shape[0],a]
      vv= km.predict(a)
      print("Predicts(",a,"):",vv)
      ```

      Out：`Predicts( [[1.  0.2 0.7 0.3 0.2]] ): [2]`

    + 函数`KMeans()`：

      ```python
      sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')
      n_clusters:K值
      init:初始K个节点的方法
      n_init:不同质心种子运行次数
      max_iter:一次运行的迭代次数
      random_state:初始化质心的随机方法
      ```

      





