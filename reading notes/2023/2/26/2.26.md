第10章 降维与度量学习
10.1 k近邻学习
k近邻学习的思想非常简单（好吧这解释了为什么我一直觉得某些算法工程师数学很菜的疑问，毕竟算法这东西有时候确实不那么需要数学…）——算算我和别人的距离，然后平均算一算，别人是啥我就是啥。

10.2 低维嵌入
然而，这样的策略也会带来问题。很明显的一点就是，如果维度仅仅为2维，那么找到一定距离内的样本是好找的，维度更高时，就可能需要很大的距离才能找到了。（可以想象样本点平均分布在一个二维平面上和三维空间内）
对于这样的问题，需要进行低维缩放，其实也就是一种变换。
能够进行这样的变换的原理是因为大多数情况下与学习任务相关的其实仅仅是某个低维分布（我的理解是，比如像你的还款能力，其实只和你的收入水平，稳定程度相关，和性别、住址什么的关系不大）
p230
