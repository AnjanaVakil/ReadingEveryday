### CHAPTER 4: DESIGN A RATE LIMITER

使用 API 速率限制器的好处：

-   通过阻止多余的调用，防止有意或无意的 DoS 攻击
-   限制调用次数对于降低成本至关重要
-   防止服务器过载。为减少服务器负载，可使用速率限制器来过滤机器人或用户不当行为造成的过多请求

#### Step 1 - Understand the problem and establish design scope

速率限制可以通过不同的算法来实现，每种算法都各有利弊。面试官和应聘者之间的互动有助于明确我们要建立的速率限制器的类型。

-   Candidate: 设计什么样的限流器？是客户端限流还是服务端限流？
-   Interviewer: 服务端
-   Candidate: 基于ip，用户id，还是其他？
-   Interviewer: 需要足够灵活支持多种

-   Candidate: 系统规模多大？小公司还是大公司？
-   Interviewer: 系统必须能处理大量的请求

-   Candidate: 分布式环境？
-   Interviewer: 是的

-   Candidate: 是独立的服务还是嵌到程序里？
-   Interviewer: 取决于你

-   Candidate: 是否要通知用户被限流？
-   Interviewer: 是

Requirements

-   准确限制过度请求
-   低延迟。速率限制器不应减慢 HTTP 响应时间
-   尽可能少用内存
-   分布式速率限制。速率限制器可由多个服务器或进程共享
-   异常处理。当用户的请求被节流时，向用户显示清晰的异常
-   高容错性。如果速率限制器出现任何问题（例如高速缓存服务器脱机 服务器脱机），也不会影响整个系统



#### Step 2 - Propose high-level design and get buy-in

##### Where to put the rate limiter?

直观地说，您可以在客户端或服务器端实施速率限制器。

-   客户端实施。一般来说，客户端是执行速率限制的不可靠场所，因为客户端请求很容易被恶意行为者伪造。此外，我们可能无法控制客户端的实现。
-   服务器端实施
    -   ![](https://inasa.dev/image/systemdesign/04/1.png)

-   除了客户端和服务器端的实现方式外，还有另一种方法。我们不在应用程序接口服务器上设置速率限制器，而是创建一个速率限制器中间件，对应用程序接口的请求进行节流。
    -   ![](https://inasa.dev/image/systemdesign/04/2.png)

![](https://inasa.dev/image/systemdesign/04/3.png)

假设我们的应用程序接口每秒允许 2 个请求，而客户端在一秒内向服务器发送了 3 个请求。请求。前两个请求被路由到 API 服务器。但是，速率限制器 中间件会对第三个请求进行节流，并返回 HTTP 状态代码 429。HTTP 429 响应状态代码表示用户发送了太多请求。

云微服务已广泛流行，而速率限制通常是在一个名为 API 网关的组件中实现的。API 网关是一种完全托管的服务，支持速率限制、SSL 终止、身份验证、IP 白名单、静态内容服务等。目前，我们只需知道 API 网关是一个支持速率限制的中间件。

在设计速率限制器时，我们要问自己的一个重要问题是：速率限制器应该在哪里实施，是在服务器端还是在网关中？这个问题没有绝对的答案。这取决于贵公司当前的技术堆栈、工程资源、优先级、目标等、 目标等。以下是几条一般准则：

-   评估当前的技术堆栈，如编程语言、缓存服务等。确保当前的编程语言能有效地在服务器端实施速率限制 的效率
-   确定适合业务需求的速率限制算法。在服务器端实施一切时，可以完全控制算法。但是，如果使用第三方网关，如果使用第三方网关，选择可能会受到限制
-   如果已经使用了微服务架构，并在设计中加入了 API 网关来执行身份验证、IP 白名单等功能，可以在 API 网关添加速率限制器
-   建立自己的费率限制服务需要时间。如果没有足够的 工程资源来实施速率限制器，商业 API 网关是更好的选择

##### Algorithms for rate limiting

速率限制可以通过不同的算法实现，每种算法都有不同的优缺点。

-   Token bucket令牌桶
-   Leaking bucket漏桶
-   Fixed window counter固定窗口计数器
-   Sliding window log滑动窗口日志
-   Sliding window counter滑动窗口计数器

###### Token bucket algorithm

![](https://inasa.dev/image/systemdesign/04/4.png)

令牌桶算法被广泛用于限制速率。它简单易懂，被互联网公司普遍采用。亚马逊和 Stripe都使用这种算法来限制其 API 请求。

令牌桶算法的工作原理如下：

-   令牌桶是一个具有预定容量的容器。令牌按预先设定的比率定期放入桶。一旦桶满，就不再添加令牌。令牌桶的容量是 4。每秒钟放入 2 个令牌。一旦桶满，多余的令牌就会溢出
-   每个请求消耗一个令牌。当一个请求到达时，我们会检查程序桶中是否有足够的令牌
    -   如果有足够的令牌，我们就会为每个请求取出一个令牌，然后请求就会通过
    -   如果没有足够的令牌，则放弃请求

​			![](https://inasa.dev/image/systemdesign/04/5.png)

桶大小为 4，填充速度为每 1 分钟 4 个

![](https://inasa.dev/image/systemdesign/04/6.png)

令牌桶算法需要两个参数：

-   桶大小：桶中允许的最大令牌数量
-   补给率：每秒放入桶的令牌数量

我们需要多少个桶？这取决于速率限制规则。下面是几个例子

-   通常有必要为不同的应用程序接口端点设置不同的存储桶。例如，如果允许用户每秒发表 1 篇文章，每天添加 150 个好友，每秒喜欢 5 篇文章，那么每个用户就需要 3 个桶
-   如果我们需要根据 IP 地址来限制请求，那么每个 IP 地址都需要一个桶
-   如果系统每秒最多允许 10,000 个请求，那么就应该有一个所有请求共享的全局存储桶

Pros

-   容易实现
-   高效内存
-   令牌桶允许短时间内的突发流量。只要还有令牌，请求就能通过

Cons

-   该算法的两个参数是水桶大小和令牌填充率。不过，要适当调整这两个参数可能很有难度



###### Leaking bucket algorithm

漏桶算法与令牌桶类似，只是以固定速率处理请求。它通常使用先进先出队列（FIFO）来实现。

-   请求到达时，系统会检查队列是否已满。如果队列未满，则将请求添加到队列中
-   否则，请求将被丢弃
-   从队列中提取请求并定期处理

![](https://inasa.dev/image/systemdesign/04/7.png)

漏桶算法需要以下两个参数：

-   桶大小：等于队列大小。队列容纳以固定速率处理的请求
-   流出速率：它定义了以固定速率（通常以秒为单位）可处理的请求数量

电子商务公司 Shopify 使用泄漏桶限制费率 

Pros

-   由于队列大小有限，因此内存效率高
-   请求以固定速率处理，因此适用于需要稳定流出速率的用例

Cons

-   突发流量会将队列中的旧请求填满，如果这些请求没有得到及时处理 新请求就会受到速率限制
-   算法中有两个参数。要正确调整它们可能并不容易



###### Fixed window counter algorithm

-   该算法将时间线划分为固定大小的时间窗口，并为每个窗口分配一个计数器
-   每次请求都会使计数器递增一个
-   一旦计数器达到预定义的阈值，新请求将被放弃，直到新的时间窗口开始

![](https://inasa.dev/image/systemdesign/04/8.png)

时间单位为 1 秒，系统每秒最多允许 3 个请求。在每秒钟的窗口中，如果收到的请求超过 3 个，系统就会丢弃多余的请求。

这种算法的一个主要问题是，时间窗口边缘的突发流量可能会导致超过允许配额的请求通过。请考虑以下情况：

系统每分钟最多允许 5 个请求，可用配额在人性化的整点重置。2:00:00 到 2:01:00 之间有 5 个请求，2:01:00 到 2:02:00 之间又有 5 个请求。在 2:00:30 和 2:01:30 之间的一分钟窗口中，有 10 个请求通过。这是允许请求数的两倍。请求的两倍。

![](https://inasa.dev/image/systemdesign/04/9.png)

Pros

-   高效内存
-   容易理解
-   在单位时间窗口结束时重置可用配额符合某些使用情况

Cons

-   窗口边缘的流量高峰可能会导致超过允许配额的请求通过



###### Sliding window log algorithm

如前所述，固定窗口计数器算法有一个主要问题：它允许更多请求在窗口边缘通过。滑动窗口日志算法解决了这个问题。

-   该算法会跟踪请求时间戳。时间戳数据通常保存在缓存中，如 Redis 的排序集
-   当有新请求时，删除所有过期的时间戳。过时的时间戳是指比当前时间窗口开始时间更早的时间戳
-   在日志中添加新请求的时间戳
-   如果日志大小与允许计数相同或更小，则接受请求。否则，请求将被拒绝

![](https://inasa.dev/image/systemdesign/04/10.png)

速率限制器允许每分钟 2 次请求。通常，Linux 时间戳会存储在日志中。不过，为了提高可读性，我们在示例中使用了人类可读的时间表示法。

-   当新请求在 1:00:01 到达时，日志为空。因此，该请求是允许的
-   新请求在 1:00:30 到达，1:00:30 的时间戳会被插入日志。插入后插入后，日志大小为 2，不大于允许计数。因此，该请求是允许的
-   新请求在 1:00:50 到达，时间戳被插入日志。插入后，日志大小为 3，大于允许的 2。因此，该请求被拒绝 尽管时间戳仍保留在日志中
-   新请求在 1:01:40 到达。在[1:00:40,1:01:40]范围内的请求都在最新时间范围内，但在 1:00:40 之前发送的请求已经过时。两个过时的时间戳、 1:00:01 和 1:00:30 将从日志中删除。删除操作后，日志大小 变为 2，因此请求被接受

Pros

-   该算法实现的速率限制非常精确。在任何滚动窗口中请求都不会超过速率限制

Cons

-   该算法会消耗大量内存，因为即使请求被拒绝，其时间戳仍可能存储在内存中



###### Sliding window counter algorithm

滑动窗口计数器算法是一种混合方法，结合了固定窗口计数器和滑动窗口日志。该算法可以通过两种不同的方法实现方法实现。

![](https://inasa.dev/image/systemdesign/04/11.png)

假设速率限制器每分钟最多允许 7 个请求，前一分钟有 5 个请求，当前一分钟有 3 个请求。对于在当前一分钟内到达 30% 位置的新请求，滚动窗口中的请求数按以下公式计算：

-   当前窗口的申请量 + 上一个窗口的申请量 * 滚动窗口与上一个窗口的重叠百分比
-   根据这一公式，我们可以得出 3 + 5 * 0.7% = 6.5 个请求。根据使用情况，该数字可以向上或向下舍入。在我们的例子中，四舍五入为 6

由于速率限制器每分钟最多允许 7 个请求，因此当前请求可以通过。不过，再收到一个请求后就会达到限制。

Pros

-   由于速率是基于前一个窗口的平均速率，因此可以平滑流量峰值
-   高效内存

Cons

-   它只适用于不太严格的回视窗口。它只是实际速率的近似值，因为它假定前一个窗口中的请求是均匀分布的。不过，这个问题可能没有想象中那么严重。根据 Cloudflare 所做的实验，在 4 亿个请求中，只有 0.003% 的请求被错误允许或速率受限

##### High-level architecture

速率限制算法的基本思想很简单。在高层次上，我们需要一个计数器来跟踪来自同一用户、IP 地址等的请求数量。如果计数器大于限制，请求就会被禁止。

计数器存放在哪里？使用数据库不是一个好主意，因为磁盘访问速度太慢。选择内存缓存是因为它速度快，而且支持基于时间的过期策略。例如，Redis是实现速率限制的常用选择。它是一种内存存储，提供两种命令：INCR 和 EXPIRE： INCR 和 EXPIRE。

-   INCR: It increases the stored counter by 1.
-   EXPIRE: It sets a timeout for the counter. If the timeout expires, the counter is automatically deleted.

![](https://inasa.dev/image/systemdesign/04/12.png)



Pp. 51-63