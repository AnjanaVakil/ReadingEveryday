限速器可以控制客户端发送流量的速度在http中是可以控制一段时间内发送请求的次数。如果超过设定阈值，多余的请求就会被丢弃
生活中的例子：
- 一个用户每分钟只能发送两个帖子
- 同一ip每天最多创建是个用户
限流有哪些好处呢
- 防止dos攻击
- 降低成本
- 防止资源被耗尽

#### 限速器应该放在哪里
##### 客户端
放在客户端时不安全的 因为客户端请求很容易被恶意伪造 不是特别好
比如说客户端程序限制发送速率 但是恶意攻击者不按照这个规则请求
##### 服务端
![[Pasted image 20230811130243.png]]
在服务端限速是安全的

##### 中间件
![[Pasted image 20230811130315.png]]
提供一个单独的限速中间件

假设我们的API允许每秒发送2个请求，而客户端在一秒内发送了3个请求到服务器。前两个请求被路由到API服务器。然而，速率限制器中间件会限制第三个请求，并返回HTTP状态码429。HTTP 429响应状态码表示用户发送了过多的请求。

云微服务[4]已经变得非常流行，速率限制通常在一个称为API网关的组件中实现。API网关是一个完全托管的服务，支持速率限制、SSL终止、身份验证、IP白名单、提供静态内容等。现在，我们只需要知道API网关是一个支持速率限制的中间件。

在设计速率限制器时，一个重要的问题是：应该在服务器端还是网关中实现速率限制器？这没有绝对的答案。它取决于您公司的当前技术堆栈、工程资源、优先级、目标等。以下是一些常见的指导原则：

• 评估您当前的技术堆栈，例如编程语言、缓存服务等。确保您当前的编程语言在服务器端实现速率限制时是高效的。

• 确定适合您业务需求的速率限制算法。当您在服务器端实现所有内容时，您对算法有完全控制。然而，如果使用第三方网关，您的选择可能会受到限制。

• 如果您已经使用了微服务架构，并在设计中包含了API网关来执行身份验证、IP白名单等操作，您可以向API网关添加速率限制器。

• 构建自己的速率限制服务需要时间。如果您没有足够的工程资源来实现速率限制器，商业API网关是一个更好的选择。

限速器没有固定答案

#### 限速算法
##### 令牌桶
令牌桶是固定容量的容器 如果桶满了，多余的token就会被丢弃
![[Pasted image 20230811131014.png]]
上图桶的容量是4 一旦桶被装满了 令牌就会被丢弃

每个请求消耗一个令牌，如果桶中没有令牌了，则拒绝请求。直到下个时间段，继续向桶中填充新的令牌
![[Pasted image 20230811131232.png]]
令牌桶算法有两个参数：
- 桶的容量
- 补充速率
需要多少个令牌桶是不确定的，通常需要为不同的API端点使用不同的令牌桶。例如，如果允许用户每秒发布1个帖子、每天添加150个好友和每秒点赞5个帖子，则每个用户需要3个令牌桶。如果需要根据IP地址限制请求速率，则每个IP地址需要一个令牌桶。  如果系统允许每秒最多10,000个请求，则有一个全局令牌桶供所有请求共享是有意义的。

优点：
- 算法易于实现
- 占用内存小
- 令牌允许在短时间内出现突发流量。只要令牌还有剩余，请求就可以继续通过
缺点：
- 应对流量变化时，正确的调整桶大小和填充率比较困难

###### go语言实现
[Golang 标准库 限流器 time/rate 设计与实现 | Go 技术论坛 (learnku.com)](https://learnku.com/articles/49065)

##### 漏桶算法
一个请求进来放入一个桶中，如果桶满了就拒绝这个请求。
桶下面有一个漏洞，桶里的元素以固定的效率流出，其实就是一个队列
漏桶算法有两个参数，分别是桶的大小和流出率，优点是简单，缺点是效率不行![[Pasted image 20230811133322.png]]

##### 固定窗口计数器
一个时间单位处理多少请求  但是缺点是时间窗口的边缘应对流量高峰会让通过的请求数超过窗口![[Pasted image 20230811134611.png]]

##### 滑动窗口日志算法
每个请求都要保存一个请求时间，保存之后还需要删除掉过时的日志，同时判断集合中的数量是否大于阈值，如果大于阈值则丢弃请求
![[Pasted image 20230811134858.png]]
优点是准确，缺点是会占用很大内存

##### 滑动窗口计数器法
维护一个一分钟的窗口，窗口中记录请求事件  保证这个请求不超过阈值 然后检查窗口最早的事件是不是超出了时间间隔，如果是就从窗口移除

#### 使用redis实现高效计数
[Redis实现限流的几种方式 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/439093222
限速器算法的思想很简单，就是使用计数器记录限制条件的请求如果超过阈值，就拒绝这个服务请求
如果把计数器放入磁盘那么会很慢，所以应该把计数器放在内存当中。最常见的就是Redis
redis提供两种命令
- INCR：将存储的计数器增加 1。
- EXPIRE：为计数器设置超时。如果超时，计数器将自动删除。
![[Pasted image 20230811140038.png]]
客户端发送请求到限速器中间件，中间件从redis获取对应的计数值。并检查是否要进行限制。如果达到限制，请求将被发送到API服务器，同时系统会递增计数器并保存返回redis

#### 返回限速信息
为了更好的用户体验，当拒绝请求之后，需要返回给用户一个状态码
![[Pasted image 20230811141832.png]]
当前架构如上，首先限速规则是存储到磁盘上，因为要经常访问，所以可以添加到缓存中。当请求到达限速中间件。中间件会从缓存中拉取限速规则，同时把请求数据写入redis的计数器，然后判断是否超出限制。没有超出限制的话就把请求转发给后端服务器，然后超出限制又两种方案 
- 丢弃多余请求放回429 
- 把多余请求推送到消息队列，后续再进行处理

#### 分布式环境

[高性能分布式限流：Redis+Lua真香！-开源基础软件社区-51CTO.COM](https://ost.51cto.com/posts/18446)
[分布式限流：基于 Redis 实现 - 熊喵君的博客 | PANDAYCHEN](https://pandaychen.github.io/2020/09/21/A-DISTRIBUTE-GOREDIS-RATELIMITER-ANALYSIS/)
分布式环境下 是把所有服务当成一个整体去考量比如说针对IP限流，我们限制了1个IP每秒最多10个访问，不管来自这个IP地址的请求落在了哪台机器上，只要是访问了集群中的服务节点，那么都会受到限制规则的制约。 所以限流信息必须放在一个中心化的组件中
有两种主流方案
1. 网关层限流。将限流规则应用在所有流量的入口处
2. 中间件限流。每个组件都能获取实时的流量统计，从而决定是放行还是拒绝

构建分布式环境下的限速器主要考虑两个问题
- 并发问题
- 数据同步问题
1. 并发问题  限速器原理是 当有新的请求到来时 去redis中读取计数器，然后进行加一 在高并发场景，可能多个线程读到了旧的值。使用锁又会导致效率的问题  有两种解决方案 一是使用Lua脚本（在redis中执行lua脚本是原子的 当使用 `EVAL` 或 `EVALSHA` 命令执行 Lua 脚本时，Redis 会将整个脚本作为一个原子操作执行） 二是使用redis的有序集合
2. 数据同步问题
	流量较大的情况下，一个限速器是难以支撑的，我们需要多个限速器。多个限速器如何同步![[Pasted image 20230811150102.png]]
3. 兜底策略  当限速器挂了  使用自身的限速 （降级）