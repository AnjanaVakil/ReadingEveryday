为什么使用向量化

之前TiDB实现了火山模型的执行引擎。这个迭代模型使用标准数据访问接口。在各个算子之间执行open()-next()-close()，一行一行处理数据。火山模型简单且可扩展。

但是，当执行大型查询时，火山模型会带来较高的解析代价。另外，也不能重复你利用现代CPU硬件的特性，如CPU CACHE、分支预测、指令流水线。

向量化执行使用单指令在内存中执行一组连续的相似的数据项。与火山模型相比，向量化模型大大降低了解释开销。因此我们选择了向量化执行引擎。

本节中，使用表达式colA*0.8 + colB来展示基于行的执行和基于向量化执行之间的开销差距。

TIDB根据算术运算符和运算符优先级，将此表达式解析为表达式求值树。在这个树中，每个非叶子节点代表一个算术运算符，叶节点代表数据源。每个非叶节点要么是一个常量如0.8，要么是表中的一个字段如colA。节点之间的父子关系表示计算上的依赖关系：子节点的结算结果是父节点的输入数据。
