13.4 图半监督学习
这里定义了图G=(V,E)。同时W_ij代表了两个结点之间的强度。
定义“能量函数”如式13.12所示。
原则上，我们希望能量函数越小越好。
这是因为结点不相邻时，强度为0。
如果相邻，我们希望他们之间的差别越小越好。
需要注意的是，南瓜书提到了，西瓜书本节的f表示有歧义，其并不是两个矩阵的乘，而是一个行向量。
最终得到了式13.17，可利用D_i上的标记信息对未标记样本进行预测。
以上为二分类方法，同样可以得到多分类问题的标记传播方法。
其具体过程是类似的（但公式复杂了亿点点）
总的来说，图半监督学习是一种思路上很清晰的算法。
但是缺点也很明显，占用的存储太大，难以判知新样本在图中的位置。

13.5 基于分歧的方法
思想上感觉并不难，今天先开个头，之后再继续看。
这里提出了视图和视图相容性的概念，很好理解。
