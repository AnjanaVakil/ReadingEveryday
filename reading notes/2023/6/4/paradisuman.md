
## 步骤

- 初始化参数：随机初始化θ0和θ1的值。

- 计算梯度：计算损失函数对θ0和θ1的偏导数，即梯度。

- 更新参数：根据学习率（步长）乘以梯度的大小来更新θ0和θ1的值。



## 更新

1. 正向传播（Forward Propagation）：将输入样本通过神经网络进行正向传播，计算模型的预测值。


3. 计算损失函数（Loss Function）：将模型的预测值与实际值进行比较，计算损失函数的值。


5. 反向传播（Backpropagation）：根据链式法则，计算损失函数对隐藏层权重的梯度。

   - 首先，计算输出层的梯度。根据损失函数和输出层的激活函数，计算输出层的梯度。
   
   - 然后，通过反向传播，将输出层的梯度向前传递到隐藏层。根据链式法则，计算隐藏层的梯度。


4. 更新权重：根据梯度下降法的更新规则，使用隐藏层的梯度来更新隐藏层的权重。   

   - 选择一个学习率（步长），表示每次更新时参数变化的幅度。
   
   - 使用梯度下降法的更新规则，更新隐藏层的权重：
   
     ```
     新权重 = 旧权重 - 学习率 * 梯度
     ```
     
     这里的梯度是根据反向传播计算得到的隐藏层权重的梯度。

5. 重复以上步骤：重复执行步骤1到步骤4，使用不同的训练样本进行批量梯度下降更新，直到达到指定的迭代次数或损失函数收敛到一个较小的阈值。


## 数据准备

- 数据控制：一般控制比较小的范围内，防止s曲线过于平坦。

- 随机初始权重

- 经验法则：权重取节点传入数量平方根倒数。

