16.4.2 时序差分学习
看介绍，时序差分学习是比蒙特卡洛强化学习的效率更高的，让我们看看它是如何做的。
通过式16.29，我们可以发现，对于状态-动作值，我们可以进行比较实时的更新。
这是一个类似于动态规划的思路。
16.5 值函数近似
现实中的强化学习任务所面临的状态空间往往是连续的，且有无穷多个状态
一种想法是对状态空间进行离散化，但这感觉上似乎就不是很容易
这里提出了一种思路，直接对连续状态空间的值函数进行学习
