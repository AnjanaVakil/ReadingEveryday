### 2022.11.28
本日章节 第1章 1.1~1.4

无需多言，正式开始。

### 第1章 绪论
#### 1.1 引言
略

#### 1.2 基本术语
略

#### 1.3 假设空间
略  

#### 1.4 归纳偏好
终于不”略”了哈哈。因为本节的归纳偏好对我来说的确是个新词，不过好在其概念依然是通俗易懂的（毕竟这只是本入门书籍）  
不过，在书的第八页我们见到了本书第一个数学公式1.1，据说每多一个数学公式，一部视频就会有一半的观众被劝退，不知道会不会也有一半的同学在这里被本书劝退呢（笑），至少我应该不会。  
看数学公式是有技巧的——”先一眼看穿公式在讲什么，然后再观察公式的具体内容”。可能部分同学会说：”你在说什么自相矛盾的X话？”而我只能表示，这个真的是经验之谈，一个简单的”总-分”思维，可以省去学习时很多不必要的困惑。  
那么让我们”一眼看穿”这个公式的内容：算法在训练集之外所有样本的误差之和是多少？由于Markdown的限制和时间的限制，我没办法具体展开讲，但可以简单地说，这个就是将所有的训练集情况下，产生的误差进行加和，从而得到的一个结果。  
经过一番简化，最后得出了一个貌似无厘头的”NFL”定理，即得到的误差之和居然与算法无关，好在作者解答了我们的疑惑——真实的问题之中，并不是所有的子问题都同等重要，这个也是我想学一学算法的原因——和开发工作一样，算法同样是一门聚焦于实用的学科（当然很多”科研”与此无关）。

今日就到这里，晚安~

P10 To be continued