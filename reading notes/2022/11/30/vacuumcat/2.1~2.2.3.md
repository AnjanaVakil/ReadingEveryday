### 2022.11.30
本日章节 第2章 2.1~2.2.3

今天一位优秀的电气工程师离开了我们~

### 第2章 模型评估与选择
#### 2.1 经验误差与过拟合
2.1节介绍了训练误差（经验误差）、泛化误差的概念。并由此又介绍了什么叫做”过拟合”与”欠拟合”——机器把训练样本学得”太好了”，有点像学生时代那种把平时的练习题做得太好了的同学，一旦遇到新的题型就不会了，这个例子感觉很恰当啊哈哈，不知道其他同学遇没遇到过这种同学。  
图2.1就给出了过拟合、欠拟合的直观类比。这里”P=NP”可能对某些同学是个陌生的概念，可以通过百度或谷歌一下解决，我就不再进行解释了。这里的观点很简单——过拟合不可避免。  

#### 2.2 评估方法 
这里，又用到了与上面相似的例子，并给出了一条经验——测试集应尽量与训练集互斥。  
那么，当我们拿到一个数据集D的时候，应当如何去划分训练集S与测试集T呢？本节介绍了几种常用的方法： 

2.2.1 留出法  
留出法（hold-out）直接将D划分为两个互斥的集合。需注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如*在分类任务中至少要保持样本的类别比例相似*，这又和我们人类的思维不谋而合——如果你平时训练做的题又偏又怪，你该如何保证自己在测试中得到一个好成绩呢？  
此外，样本的划分也需要考虑，这里使用若干次随机划分作为划分方式。  

2.2.2 交叉验证法  
交叉验证法就比留出法看起来更加”科学”一点，每次用k-1个子集做训练，剩下的一个子集做验证，然后进行k次训练与测试，听起来非常合理。  
当然，这种方法带来的也并非全是好处——很可能导致计算开销太大，因此也不一定是坠吼的方法。


P27 To be continued